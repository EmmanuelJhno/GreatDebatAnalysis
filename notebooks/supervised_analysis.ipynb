{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "with open('../data/gdn_common_sorted.txt') as file : \n",
    "    for j, line in enumerate(file): \n",
    "        if j > 0 : \n",
    "            res.append(line.split(' ')[:701])\n",
    "res = np.asarray(res)\n",
    "embedding = pd.DataFrame(res[:,1:], index=res[:,0])\n",
    "embeded_words = {}\n",
    "\n",
    "for word in embedding.index : \n",
    "    embeded_words[word.split('_')[0]] = word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_F.csv', sep=';') # lecture data set \n",
    "department = np.copy(data['zip_code'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence): \n",
    "    '''\n",
    "    return the sentence passed in argmuents with no punctuation\n",
    "    '''\n",
    "    sentence = sentence.replace('\\'',' ').lower()\n",
    "    table = sentence.maketrans('', '', string.punctuation)\n",
    "    sentence = [w.translate(table) for w in sentence]\n",
    "    sentence = ''.join(sentence)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def embed_answer(sentence): \n",
    "    sentence_embedding = []\n",
    "    sentence = preprocess(sentence)\n",
    "    for i, word in enumerate(sentence.split(' ')):\n",
    "        try : \n",
    "            if not embeded_words[word].endswith('_i'):\n",
    "                sentence_embedding.append(embedding.loc[embeded_words[word]].tolist())\n",
    "        except KeyError: \n",
    "            continue\n",
    "    \n",
    "    return(np.asarray(sentence_embedding, dtype=np.float64))\n",
    "   \n",
    "def compute_variance(sentence_embedding, eval_type='var'):\n",
    "    result = 0\n",
    "    if eval_type == 'var':\n",
    "        for index in range(len(sentence_embedding[0])):\n",
    "            result += np.var(sentence_embedding[:,index])\n",
    "            \n",
    "    elif eval_type == 'dist':\n",
    "        n = len(sentence_embedding)\n",
    "        for word_1_idx in range(n-1):\n",
    "            for word_2_idx in range(word_1_idx+1,n):\n",
    "                result += np.linalg.norm(sentence_embedding[word_1_idx]-sentence_embedding[word_2_idx])\n",
    "        result = result*2/(n*(n-1))\n",
    "\n",
    "    return result\n",
    "\n",
    "def compute_moyenne(sentence_embedding):\n",
    "    result = []\n",
    "    #print(len(sentence_embedding[0]))\n",
    "    for index in range(len(sentence_embedding[0])): # taille 700\n",
    "        result.append(np.sum(sentence_embedding[:,index])/len(sentence_embedding))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2445/2445 [00:37<00:00, 65.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>score_0</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>score_6</th>\n",
       "      <th>score_7</th>\n",
       "      <th>score_8</th>\n",
       "      <th>...</th>\n",
       "      <th>score_690</th>\n",
       "      <th>score_691</th>\n",
       "      <th>score_692</th>\n",
       "      <th>score_693</th>\n",
       "      <th>score_694</th>\n",
       "      <th>score_695</th>\n",
       "      <th>score_696</th>\n",
       "      <th>score_697</th>\n",
       "      <th>score_698</th>\n",
       "      <th>score_699</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>-0.015336</td>\n",
       "      <td>-0.015614</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.032181</td>\n",
       "      <td>0.061739</td>\n",
       "      <td>-0.052617</td>\n",
       "      <td>0.034983</td>\n",
       "      <td>-0.054036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029986</td>\n",
       "      <td>0.039820</td>\n",
       "      <td>-0.003342</td>\n",
       "      <td>0.030171</td>\n",
       "      <td>-0.050199</td>\n",
       "      <td>0.039690</td>\n",
       "      <td>-0.009338</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>0.052214</td>\n",
       "      <td>-0.037971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>-0.016981</td>\n",
       "      <td>0.022253</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>0.041670</td>\n",
       "      <td>0.072220</td>\n",
       "      <td>-0.055472</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>-0.045204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>0.019873</td>\n",
       "      <td>-0.005545</td>\n",
       "      <td>-0.014305</td>\n",
       "      <td>-0.030772</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.039085</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>-0.034817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation   score_0   score_1   score_2   score_3   score_4   score_5  \\\n",
       "0         1.0  0.002184 -0.015336 -0.015614  0.004679  0.032181  0.061739   \n",
       "1         1.0  0.063287 -0.016981  0.022253 -0.004149  0.041670  0.072220   \n",
       "\n",
       "    score_6   score_7   score_8    ...      score_690  score_691  score_692  \\\n",
       "0 -0.052617  0.034983 -0.054036    ...       0.029986   0.039820  -0.003342   \n",
       "1 -0.055472  0.000335 -0.045204    ...       0.010781   0.019873  -0.005545   \n",
       "\n",
       "   score_693  score_694  score_695  score_696  score_697  score_698  score_699  \n",
       "0   0.030171  -0.050199   0.039690  -0.009338  -0.014119   0.052214  -0.037971  \n",
       "1  -0.014305  -0.030772   0.017193   0.039085   0.000324   0.008392  -0.034817  \n",
       "\n",
       "[2 rows x 701 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for index in tqdm.tqdm(range(len(data))):\n",
    "    answer = embed_answer(data.iloc[index]['solution'])\n",
    "    if len(answer)>1:\n",
    "        # score de taille 700\n",
    "        scores.append(compute_moyenne(answer))#,compute_variance(answer, eval_type='var'),compute_variance(answer, eval_type='dist')])\n",
    "    else:\n",
    "        scores.append([np.nan]*700)\n",
    "        \n",
    "# Total = 15309\n",
    "scores_df = pd.DataFrame(data=np.array(scores),index=data.index, columns = ['score_'+str(i) for i in range(700)]) \n",
    "argumentation_scores = pd.concat([data['annotation'],scores_df], axis=1) \n",
    "argumentation_scores.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2445, 701)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "Name: annotation, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argumentation_scores = argumentation_scores.dropna()\n",
    "print(argumentation_scores.shape)\n",
    "X = argumentation_scores.drop('annotation',axis=1)\n",
    "Y = argumentation_scores['annotation']\n",
    "X.head(2)\n",
    "Y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_1 = y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Scores on train---------------\n",
      "[[1223  206]\n",
      " [ 112  415]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.86      0.88      1429\n",
      "        1.0       0.67      0.79      0.72       527\n",
      "\n",
      "avg / total       0.85      0.84      0.84      1956\n",
      "\n",
      "1956 621.0\n",
      "0.7229965156794425\n",
      "---------------Scores on test---------------\n",
      "[[288  64]\n",
      " [ 85  52]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.82      0.79       352\n",
      "        1.0       0.45      0.38      0.41       137\n",
      "\n",
      "avg / total       0.68      0.70      0.69       489\n",
      "\n",
      "489 137.0\n",
      "0.4110671936758893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear', C=9)\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "print(15*'-' +'Scores on train' + 15*'-' )\n",
    "y_pred = svclassifier.predict(X_train)\n",
    "print(confusion_matrix(y_pred,y_train))\n",
    "print(classification_report(y_pred, y_train))\n",
    "print(len(y_train), np.sum(y_train))\n",
    "print(f1_score(y_pred,y_train))\n",
    "\n",
    "print(15*'-' +'Scores on test' + 15*'-' )\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(len(y_test), np.sum(y_test))\n",
    "print(f1_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Balanced weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Scores on train---------------\n",
      "[[1003   74]\n",
      " [ 332  547]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.93      0.83      1077\n",
      "        1.0       0.88      0.62      0.73       879\n",
      "\n",
      "avg / total       0.81      0.79      0.79      1956\n",
      "\n",
      "1956 621.0\n",
      "0.7293333333333333\n",
      "---------------Scores on test---------------\n",
      "[[222 130]\n",
      " [ 41  96]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.63      0.72       352\n",
      "        1.0       0.42      0.70      0.53       137\n",
      "\n",
      "avg / total       0.73      0.65      0.67       489\n",
      "\n",
      "489 137.0\n",
      "0.5289256198347108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear', C=5, class_weight='balanced')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "print(15*'-' +'Scores on train' + 15*'-' )\n",
    "y_pred = svclassifier.predict(X_train)\n",
    "print(confusion_matrix(y_pred,y_train))\n",
    "print(classification_report(y_pred, y_train))\n",
    "print(len(y_train), np.sum(y_train))\n",
    "print(f1_score(y_pred,y_train))\n",
    "\n",
    "print(15*'-' +'Scores on test' + 15*'-' )\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(len(y_test), np.sum(y_test))\n",
    "print(f1_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Balanced weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Scores on train---------------\n",
      "[[989  80]\n",
      " [346 541]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.93      0.82      1069\n",
      "        1.0       0.87      0.61      0.72       887\n",
      "\n",
      "avg / total       0.80      0.78      0.78      1956\n",
      "\n",
      "1956 621.0\n",
      "0.7175066312997348\n",
      "---------------Scores on test---------------\n",
      "[[218 134]\n",
      " [ 43  94]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.62      0.71       352\n",
      "        1.0       0.41      0.69      0.52       137\n",
      "\n",
      "avg / total       0.72      0.64      0.66       489\n",
      "\n",
      "489 137.0\n",
      "0.5150684931506849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear', C=9, class_weight= {0:freq_1, 1:1-freq_1})\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "print(15*'-' +'Scores on train' + 15*'-' )\n",
    "y_pred = svclassifier.predict(X_train)\n",
    "print(confusion_matrix(y_pred,y_train))\n",
    "print(classification_report(y_pred, y_train))\n",
    "print(len(y_train), np.sum(y_train))\n",
    "print(f1_score(y_pred,y_train))\n",
    "\n",
    "print(15*'-' +'Scores on test' + 15*'-' )\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(len(y_test), np.sum(y_test))\n",
    "print(f1_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9802533630>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZh0lEQVR4nO3de5Bc5Xnn8e9zuntuGt1nwEIXJBDYFoXXYEUBr+14zZICl4NSWagIbyX8QUrJrqndlHcrC5VdyqZclZDamDgxtQkVSBHHGyAkXqscObIDybpMWJkR5iKBZQYElsRtNJJGl9Foeqaf/eO8PTp9psW00Mx0zzu/TzGc29vdTw/N77zzntPnmLsjIiLxSppdgIiIzCwFvYhI5BT0IiKRU9CLiEROQS8iErliswvI6+np8bVr1za7DBGROWXXrl2H3L233raWC/q1a9fS19fX7DJEROYUM3vjbNs0dCMiEjkFvYhI5BT0IiKRU9CLiEROQS8iEjkFvYhI5BT0IiKRiybo3xo6xR9+by+vDZxodikiIi0lmqB/59hp/uTJfl4fPNnsUkREWko0QZ9YOtV9VEREakUT9Eaa9BUFvYhIjXiCfqJHr6QXEclqKOjN7AYz22tm/WZ2Z53t7Wb2aNi+08zWhvUlM3vYzF40s5fN7K7pLX8yxbyISK0pg97MCsD9wI3ABuBWM9uQa3Y7cMTd1wP3AfeG9bcA7e5+JfAx4DerO4HploQuvTr0IiK1GunRbwL63f01dx8FHgE259psBh4O848D15mZkXawF5hZEegERoFj01J5joZuRETqayToVwL7M8sHwrq6bdx9DBgClpOG/kngLeBnwP9098P5FzCzrWbWZ2Z9AwMD5/wm0udIp4p5EZFaM30wdhMwDlwErAP+i5ldkm/k7g+4+0Z339jbW/cGKVOqnnWjDr2ISK1Ggv4gsDqzvCqsq9smDNMsBgaBzwP/4O5ld38XeArYeL5F1zNxHr369CIiNRoJ+meAy8xsnZm1AVuAbbk224DbwvzNwJOeDpb/DPgMgJktAK4BfjIdhedVh250Hr2ISK0pgz6Mud8B7ABeBh5z9z1mdo+Z3RSaPQgsN7N+4ItA9RTM+4FuM9tDusP4C3d/YbrfRKo6dKOkFxHJaujm4O6+HdieW3d3Zn6E9FTK/ONO1Fs/E6o9ehERqRXNN2N1Hr2ISH3RBH21Q19R0ouI1Ign6HX1ShGRuuIJ+urB2CbXISLSauIJel0CQUSkrgiDvrl1iIi0moiCvjp0o6QXEcmKJ+jDVD16EZFa0QT9xHn0Ta5DRKTVRBP0Z651o6gXEcmKJ+jDVDkvIlIrmqBHNx4REakrmqA3dH6liEg90QR9ouvRi4jUFU3QT5xHrx69iEiNeII+TBXzIiK14gl6DdGLiNQVUdDrC1MiIvVEFPTpVGP0IiK14gn6MFXOi4jUiifodfVKEZG6ogn6RAdjRUTqiiboq9+M1RemRERqxRP0E9e6UdKLiGRFE/RVGroREakVTdBXbzwiIiK1ogn6iRuPaJBeRKRGPEEfpop5EZFa8QT9xNUrm1yIiEiLiSboE511IyJSVzRBX+3Ra4heRKRWNEE/QWM3IiI1ogp6Mx2MFRHJiyroEzN16EVEcqIKegMqSnoRkRpxBb2GbkREJokr6NHQjYhIXlxBbzqPXkQkr6GgN7MbzGyvmfWb2Z11treb2aNh+04zW5vZ9hEze9rM9pjZi2bWMX3l5+vQ2ZUiInlTBr2ZFYD7gRuBDcCtZrYh1+x24Ii7rwfuA+4Njy0CfwX8lrtfAXwaKE9b9flaMd0cXEQkp5Ee/Sag391fc/dR4BFgc67NZuDhMP84cJ2lX1X9ReAFd38ewN0H3X18ekqfTD16EZHJGgn6lcD+zPKBsK5uG3cfA4aA5cDlgJvZDjN71sx+5/xLPrvETCP0IiI5xVl4/k8APwcMA0+Y2S53fyLbyMy2AlsB1qxZ875fTOfRi4hM1kiP/iCwOrO8Kqyr2yaMyy8GBkl7/z9w90PuPgxsB67Ov4C7P+DuG919Y29v77m/iyoN3YiITNJI0D8DXGZm68ysDdgCbMu12QbcFuZvBp709KjoDuBKM+sKO4BfAF6antIn080ERUQmm3Loxt3HzOwO0tAuAA+5+x4zuwfoc/dtwIPAN8ysHzhMujPA3Y+Y2VdJdxYObHf3v5+h90KS6KwbEZG8hsbo3X076bBLdt3dmfkR4JazPPavSE+xnHHpGP1svJKIyNwR2TdjTd+MFRHJiSvo0cFYEZG8uIJe59GLiEwSWdCjg7EiIjlxBT0auhERyYsr6PWFKRGRSaIK+kRn3YiITBJV0Os8ehGRyeIKetOtBEVE8qIKetCtBEVE8qIK+iQB5byISK2ogt4wXY9eRCQnrqA3dehFRPLiCnp0Hr2ISF5UQa97xoqITBZV0GO6Z6yISF5UQW+gQXoRkZy4gl6XQBARmSSuoEcHY0VE8qIK+sR0Hr2ISF5UQa/LFIuITBZV0IOOxYqI5EUV9Lp6pYjIZFEFfaLzK0VEJokq6M104xERkby4gh7DNXYjIlIjrqDX1StFRCaJLOh1MFZEJC+uoEcXNRMRyYsr6K3ZFYiItJ6ogj4xY1yn3YiI1Igq6EsFY2xcQS8ikhVZ0CeUK5VmlyEi0lKiC3r16EVEakUV9MXEKI+rRy8ikhVV0JcKiYJeRCQnsqA3xnTWjYhIjaiCvlhIKI+pRy8ikhVV0JcKRlk9ehGRGg0FvZndYGZ7zazfzO6ss73dzB4N23ea2drc9jVmdsLM/uv0lF1fetaNevQiIllTBr2ZFYD7gRuBDcCtZrYh1+x24Ii7rwfuA+7Nbf8q8N3zL/e9FZOEsk6vFBGp0UiPfhPQ7+6vufso8AiwOddmM/BwmH8cuM4svfKMmf0ysA/YMz0ln12poNMrRUTyGgn6lcD+zPKBsK5uG3cfA4aA5WbWDfw34Mvv9QJmttXM+sysb2BgoNHaJ9HplSIik830wdgvAfe5+4n3auTuD7j7Rnff2Nvb+75frFgwKg4VHZAVEZlQbKDNQWB1ZnlVWFevzQEzKwKLgUHg54GbzewPgCVAxcxG3P3r5115HaVCut8qVyq0J4WZeAkRkTmnkaB/BrjMzNaRBvoW4PO5NtuA24CngZuBJz29eesnqw3M7EvAiZkKeUjH6AHK4057I+9MRGQemDIO3X3MzO4AdgAF4CF332Nm9wB97r4NeBD4hpn1A4dJdwazrpikPXqdYikickZD/V533w5sz627OzM/AtwyxXN86X3Ud06yPXoREUlF9s3YMEavHr2IyISogr5YqA7dqEcvIlIVVdBXh25G1aMXEZkQVdD3dLcD8PbQSJMrERFpHVEF/YdXLALgpbeGmlyJiEjriCroly1oY/mCNl4fHG52KSIiLSOqoAdoLyaM6uYjIiITogv6YiFhXNe6ERGZEGHQ61LFIiJZ0QV9KUl0Hr2ISEZ0QV9IjLGKevQiIlXRBX16lyn16EVEqqIL+mIhUY9eRCQjvqBP1KMXEcmKLuhLOr1SRKRGdEFfLJhuPCIikhFf0GvoRkSkRoRBr4OxIiJZ8QV9wfSFKRGRjOiCvlRIKKtHLyIyIbqgLybq0YuIZMUX9AVjTKdXiohMiC/ok0SnV4qIZMQX9DoYKyJSI7qg18FYEZFa0QW9DsaKiNSKL+gLCWMVx11hLyICMQZ9YgA680ZEJIgu6NuL6Vs6PaZxehERiDDoly5oA+DIydEmVyIi0hqiC/qe7jToD5043eRKRERaQ4RB3w7AoRPq0YuIQIRBvzwE/aB69CIiQIxBH8boBzVGLyICRBj0HaUCC9uLDBxXj15EBCIMeoDl3W3q0YuIBFEGfU93u8boRUSCKIN+eXebTq8UEQkiDfp2BnV6pYgI0GDQm9kNZrbXzPrN7M4629vN7NGwfaeZrQ3rrzezXWb2Yph+ZnrLr6+nu53Dw6OM63o3IiJTB72ZFYD7gRuBDcCtZrYh1+x24Ii7rwfuA+4N6w8Bv+TuVwK3Ad+YrsLfS093G+5wZFi9ehGRRnr0m4B+d3/N3UeBR4DNuTabgYfD/OPAdWZm7v5jd38zrN8DdJpZ+3QU/l6WL6h+O1bj9CIijQT9SmB/ZvlAWFe3jbuPAUPA8lybfwc86+6T0tfMtppZn5n1DQwMNFr7WVWvd6NxehGRWToYa2ZXkA7n/Ga97e7+gLtvdPeNvb295/16vQvTHv07x0bO+7lEROa6RoL+ILA6s7wqrKvbxsyKwGJgMCyvAr4F/Lq7v3q+BTdi1dIuEoPXD52cjZcTEWlpjQT9M8BlZrbOzNqALcC2XJttpAdbAW4GnnR3N7MlwN8Dd7r7U9NV9FTaigmrlnbxmoJeRGTqoA9j7ncAO4CXgcfcfY+Z3WNmN4VmDwLLzawf+CJQPQXzDmA9cLeZPRd+Lpj2d1HH2p4FvDE4PBsvJSLS0oqNNHL37cD23Lq7M/MjwC11HvcV4CvnWeP7snJJJ3sODjXjpUVEWkqU34wFWLmkg8GTo4yUx5tdiohIU0Ub9CsWdwLw1pDOvBGR+S3aoP/A4g5Ap1iKiEQb9Eu6SgAc1WUQRGSeizbol4VbCh4ZLje5EhGR5oo26Jd2pUF/WHeaEpF5Ltqg7ygV6CwVOKKgF5F5Ltqgh3T4RveOFZH5Luqg//CKRex640izyxARaaqog/7TH+zlZ4eH+ZdXDzW7FBGRpok66G/+2CoWd5b41rP5i22KiMwfUQd9R6nAz61dSp+Gb0RkHos66AE+sb6HfYdO8so7x5tdiohIU0Qf9J/9yAoSg23Pvzl1YxGRCEUf9Bcs7ODaS5ez7fk3cfdmlyMiMuuiD3qAm/7VRbwxOMyeN481uxQRkVk3L4L+mkuWA/CSgl5E5qF5EfSrlnbRVkzoHzjR7FJERGbdvAj6QmJc2tvNnjd1a0ERmX/mRdADfOqyHn607zDHRnTZYhGZX+ZN0F+/4ULK486O3W83uxQRkVk1b4L+qjVLWb2sk//x7d28cOBos8sREZk18yboC4nx+G99nGKS8NXv/7TZ5YiIzJp5E/QAFy7q4LoPX8A/7x1gxx4N4YjI/DCvgh7g937lSrraCvzut17k0InTzS5HRGTGzbug72or8rUtVzF4cpQvfPNZxsYrzS5JRGRGzbugh/QMnC/fdAU79x3m9777E4aGdcqliMRrXgY9wK9dczG//NGLePCH+7jlz/6Fsnr2IhKpeRv0ZsYfbbmKr3/+Kn76zgm+8M1nOT023uyyRESm3bwN+qrPfeQivnzTFXzvpXfY+pe7GB4da3ZJIiLTat4HPcBtH1/L7//KlfzglQGu+8P/y1e+8xJHh0ebXZaIyLQoNruAVrFl0xouvaCbP37iFR58ah8PP/06v3D5BfzatRfzqct6MLNmlygi8r5Yq911aePGjd7X19fUGnYfHOLbzx3ksb4DDJ0qc+XKxfzGJ9fxbz98IQvatW8UkdZjZrvcfWPdbQr6sxspj/PoM/t56Kl9vDE4TKlgXLVmKZ9c38MnL+9lw4pFtBU1+iUizaegP0/l8QrP7DvMD145xA/7B9h9ML1TVTExNq1bxvoLurly5WKu33AhiztLGuYRkVmnoJ9mgydO89Srg+w+OMQPfjrAm0dPcWwkPVunvZhw+YUL+dAHFnJJbzerl3WyamkXq5d2smxBm3YCIjIjFPQzzN15+rVBXn7rOG8PneKlt46x9+0Tk66l09VWYNXSTi5evoA1y7q4aEknFy3u4IJFHfR2t9OzsI2uNh0DEJFz915Br1SZBmbGxy/t4eOX9tSsPz5S5uDRU+w/fIoDR4Y5cOQU+w8Ps+/QSX74yiFOlSd/QWtBW4ELF3XQs7CdxZ0lFnWUWNRZDNMSizqKLMysq7bp7ihSSPTXgohMpqCfQQs7SnzoAyU+9IFFk7a5O0eHy7w5dIp3j59m4PhpDp1Ip+8eP83AsdPsPzzM8ZExjp0qc/z01F/k6m4vsqijGHYI6c5gYUeJrrYCXW0FOksFOsK0s1Sgo1Sgo5TQXizQXkxoL6XTeuvai4mGnUTmqIaC3sxuAL4GFIA/d/ffz21vB/4S+BgwCPyqu78ett0F3A6MA//J3XdMW/VzmJmxdEEbSxe0cUUD7ccrzomRMY6NlBk6VU53ACNljp0qcyzsDI6NlCd2DMdGyrx5dIRjI8c5NTrOqXL6cz4jdW3FhI5c+LcXMzuLUp11xYT2UkJH2N5WSCgWqlOjVEgohWkxO5+k00JilApGManOp9NiYhQKYZqk2xNDOyOROqYMejMrAPcD1wMHgGfMbJu7v5RpdjtwxN3Xm9kW4F7gV81sA7AFuAK4CPhHM7vc3XVRmXNUSIzFXSUWd5VY/T6fw905PVapCf7T5Qqnx8Y5PVZJf8rp/Eg5s26s2i67PkzLZ7YfOTla8zwjmecbq8zOsaAzwR+mmR1DYkaxkN2eTGqf/ak+JrsuMcMMDCMxSMxIEiC7HHY4FpYNSJLccmiHTfG47PJZ2iWhHsvUk12e9Djqt5t4b7nlSY+bot2k2pP8ez7zuInak8bes7w/jfToNwH97v4agJk9AmwGskG/GfhSmH8c+Lql/1U2A4+4+2lgn5n1h+d7enrKl3NhZmG4psDSWX7tsfEKo+PpjqFcqVAed8bGK5THK4yOOWOVdL487pTHK4yNO2OV0KbijIfHjId145V0++RpulMZHz/L+rBcqfe48XRHOF5xKp5um/gJy+5Q8cnTdD+WTiuePr/DWds7Z5alcfmdW/iH6j6guuNK58/sHGziXxOTiZ1lvbZn9in5Nmdep1pP9vmydTZUU5ipzv+bD17Af//chnP5lTSkkaBfCezPLB8Afv5sbdx9zMyGgOVh/f/LPXZl/gXMbCuwFWDNmjWN1i5zSDEMzXS1NbuS1uOe2UGE8PfsMuCV2h1E3Xb1Hhee+73a1eykKrU7ofzUcSqV+ju3s+7UPF87UPOe0zrr7QSz9dR9HA5hZ1l9v+nvdGL1RN3V+ezv/czjqs/hmfls+8z6KdqetaaaNmdqyLwEK5Z0Tvl5eT9a4mCsuz8APADp6ZVNLkdkVpkZBYPCmT6eyLRq5Pv7B6FmWHhVWFe3jZkVgcWkB2UbeayIiMygRoL+GeAyM1tnZm2kB1e35dpsA24L8zcDT3r698o2YIuZtZvZOuAy4EfTU7qIiDRiyqGbMOZ+B7CD9PTKh9x9j5ndA/S5+zbgQeAb4WDrYdKdAaHdY6QHbseAL+iMGxGR2aVLIIiIROC9LoGga+yKiEROQS8iEjkFvYhI5BT0IiKRa7mDsWY2ALxxHk/RAxyapnJm2lyqFeZWvXOpVphb9c6lWmFu1Xs+tV7s7r31NrRc0J8vM+s725HnVjOXaoW5Ve9cqhXmVr1zqVaYW/XOVK0auhERiZyCXkQkcjEG/QPNLuAczKVaYW7VO5dqhblV71yqFeZWvTNSa3Rj9CIiUivGHr2IiGQo6EVEIhdN0JvZDWa218z6zezOZtcDYGYPmdm7ZrY7s26ZmX3fzF4J06VhvZnZH4f6XzCzq2e51tVm9k9m9pKZ7TGz/9zi9XaY2Y/M7PlQ75fD+nVmtjPU9Wi4tDbhUtmPhvU7zWztbNYbaiiY2Y/N7DtzoNbXzexFM3vOzPrCulb9LCwxs8fN7Cdm9rKZXdvCtX4w/E6rP8fM7LdnvN70Fl5z+4f08smvApcAbcDzwIYWqOtTwNXA7sy6PwDuDPN3AveG+c8C3yW9feQ1wM5ZrnUFcHWYXwj8FNjQwvUa0B3mS8DOUMdjwJaw/k+B/xDm/yPwp2F+C/BoEz4PXwT+N/CdsNzKtb4O9OTWtepn4WHgN8J8G7CkVWvN1V0A3gYunul6m/IGZ+AXdi2wI7N8F3BXs+sKtazNBf1eYEWYXwHsDfN/Btxar12T6v42cP1cqBfoAp4lvZfxIaCY/1yQ3k/h2jBfDO1sFmtcBTwBfAb4TvgftyVrDa9bL+hb7rNAeje7ffnfTyvWWqf2XwSemo16Yxm6qXcD80k3IW8RF7r7W2H+beDCMN8y7yEMFVxF2ktu2XrDUMhzwLvA90n/qjvq7mN1aqq5gT1QvYH9bPkj4HeASlheTuvWCun9q79nZrvMbGtY14qfhXXAAPAXYVjsz81sQYvWmrcF+OswP6P1xhL0c5Knu+iWOr/VzLqBvwV+292PZbe1Wr3uPu7uHyXtLW8CPtTkkuoys88B77r7rmbXcg4+4e5XAzcCXzCzT2U3ttBnoUg6PPq/3P0q4CTp0MeEFqp1QjgecxPwN/ltM1FvLEE/l25C/o6ZrQAI03fD+qa/BzMrkYb8N93978Lqlq23yt2PAv9EOvyxxNIb1OdrOtsN7GfDvwZuMrPXgUdIh2++1qK1AuDuB8P0XeBbpDvSVvwsHAAOuPvOsPw4afC3Yq1ZNwLPuvs7YXlG640l6Bu5gXmryN5I/TbSsfDq+l8PR9mvAYYyf8rNODMz0nv/vuzuX50D9faa2ZIw30l6POFl0sC/+Sz11ruB/Yxz97vcfZW7ryX9bD7p7v++FWsFMLMFZrawOk86lrybFvwsuPvbwH4z+2BYdR3pPapbrtacWzkzbFOta+bqbcZBiBk6sPFZ0jNFXgV+t9n1hJr+GngLKJP2PG4nHWt9AngF+EdgWWhrwP2h/heBjbNc6ydI/1x8AXgu/Hy2hev9CPDjUO9u4O6w/hLgR0A/6Z/F7WF9R1juD9svadJn4tOcOeumJWsNdT0ffvZU/39q4c/CR4G+8Fn4P8DSVq011LCA9C+0xZl1M1qvLoEgIhK5WIZuRETkLBT0IiKRU9CLiEROQS8iEjkFvYhI5BT0IiKRU9CLiETu/wPIKulHgIYfjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=700)\n",
    "pca.fit_transform(X_train)\n",
    "plt.plot(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40)\n",
    "pca.fit_transform(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Scores on train---------------\n",
      "[[820 133]\n",
      " [515 488]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.86      0.72       953\n",
      "        1.0       0.79      0.49      0.60      1003\n",
      "\n",
      "avg / total       0.70      0.67      0.66      1956\n",
      "\n",
      "1956 621.0\n",
      "0.6009852216748769\n",
      "---------------Scores on test---------------\n",
      "[[213 139]\n",
      " [ 29 108]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.61      0.72       352\n",
      "        1.0       0.44      0.79      0.56       137\n",
      "\n",
      "avg / total       0.76      0.66      0.67       489\n",
      "\n",
      "489 137.0\n",
      "0.5625000000000001\n"
     ]
    }
   ],
   "source": [
    "## from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear', C=11e1, class_weight= 'balanced')\n",
    "svclassifier.fit(X_train_pca, y_train)\n",
    "\n",
    "print(15*'-' +'Scores on train' + 15*'-' )\n",
    "y_pred = svclassifier.predict(X_train_pca)\n",
    "print(confusion_matrix(y_pred,y_train))\n",
    "print(classification_report(y_pred, y_train))\n",
    "print(len(y_train), np.sum(y_train))\n",
    "print(f1_score(y_pred,y_train))\n",
    "\n",
    "print(15*'-' +'Scores on test' + 15*'-' )\n",
    "y_pred = svclassifier.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(len(y_test), np.sum(y_test))\n",
    "print(f1_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best f1 : 6.03e-01 |  for C = 1.20e+00 with 313 components:   8%|▊         | 66/800 [15:33<2:56:55, 14.46s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-649f77f86e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msvclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlog_10_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0msvclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cv_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "n_split = 10\n",
    "n_val = 800\n",
    "cv_parameters = {'log_10_C': [-1, 2],\n",
    "                 'n_comp':[10, 400] }\n",
    "scores = []\n",
    "log_10_cs = []\n",
    "n_comps = []\n",
    "\n",
    "progress_bar = trange(n_val, desc='Bar desc', leave=True)\n",
    "for n in progress_bar:\n",
    "    log_10_c = np.random.random() * (cv_parameters['log_10_C'][1] - cv_parameters['log_10_C'][0]) + cv_parameters['log_10_C'][0]\n",
    "    n_comp = int(np.random.random() * (cv_parameters['n_comp'][1] - cv_parameters['n_comp'][0]) + cv_parameters['n_comp'][0])\n",
    "    n_comps.append(n_comp)\n",
    "    log_10_cs.append(log_10_c)\n",
    "    f1_mean = []\n",
    "    for split in range(n_split): \n",
    "        \n",
    "        X_cv_train, X_val, y_cv_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=split)\n",
    "        \n",
    "        pca = PCA(n_components=n_comp)\n",
    "        \n",
    "        pca.fit_transform(X_train)\n",
    "        X_train_pca = pca.transform(X_cv_train)\n",
    "        X_test_pca = pca.transform(X_val)\n",
    "        \n",
    "        svclassifier = SVC(kernel='linear', C=10**log_10_c, class_weight= 'balanced')\n",
    "        svclassifier.fit(X_train_pca, y_cv_train)\n",
    "        \n",
    "        y_pred = svclassifier.predict(X_test_pca)\n",
    "        f1_mean.append(f1_score(y_pred,y_val))\n",
    "    scores.append(np.mean(f1_mean))\n",
    "    i_max = scores.index(max(scores))\n",
    "    progress_bar.set_description('best f1 : {:.2e} |  for C = {:.2e} with {} components'.format(scores[i_max], 10**log_10_cs[i_max], n_comps[i_max]))\n",
    "    progress_bar.refresh()\n",
    "    \n",
    "        \n",
    "i_max = scores.index(max(scores))\n",
    "print('best f1 : {:.2e} |  for C = {:.2e} with {} components'.format(scores[i_max], 10**log_10_cs[i_max], n_comps[i_max]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switching from mean to Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principal_components(sentence, k=5):\n",
    "    pca = PCA(n_components=k)\n",
    "    pcs = pca.fit_transform(X_train)\n",
    "    return pcs.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "k = 5\n",
    "for index in tqdm.tqdm(range(len(data))):\n",
    "    answer = embed_answer(data.iloc[index]['solution'])\n",
    "    if len(answer)>k:\n",
    "        scores.append(get_principal_components(answer))#,compute_variance(answer, eval_type='var'),compute_variance(answer, eval_type='dist')])\n",
    "    else:\n",
    "        scores.append([np.nan]*700*k)\n",
    "        \n",
    "# Total = 15309\n",
    "scores_df = pd.DataFrame(data=np.array(scores),index=data.index, columns = ['score_'+str(i) for i in range(700)]) \n",
    "argumentation_scores = pd.concat([data['annotation'],scores_df], axis=1) \n",
    "argumentation_scores.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
